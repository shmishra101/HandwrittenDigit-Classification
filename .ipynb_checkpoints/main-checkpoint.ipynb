{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shmis\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Project 3------------\n",
      "UBIT NAME : mishra3\n",
      "UBIT Person Number: 50290757\n"
     ]
    }
   ],
   "source": [
    "print('-------------Project 3------------')\n",
    "print('UBIT NAME : mishra3')\n",
    "print('UBIT Person Number: 50290757')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One to 10 encoding is used so that our model can predict the class\n",
    "# Every Target value is converted into 1X10 matrix.All the entries of matrix is zero except the position equivalent to target value is set to 1\n",
    "# e.g if Target value is 2 then Target value become 0010000000\n",
    "def encodeTarget(target):\n",
    "    encode_target=np.zeros((len(target),10))\n",
    "    for i in range(0,len(target)):\n",
    "        num=int(target[i])\n",
    "        encode_target[i][num]=1\n",
    "    return encode_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Data Generated\n"
     ]
    }
   ],
   "source": [
    "dataframe=pd.read_csv('MNIST.csv')\n",
    "# Shuffling the dataset\n",
    "shuffledata = np.array(dataframe.sample(frac=1))\n",
    "# Setting the Training length as 80%\n",
    "traininglength=int(0.8*(len(shuffledata)+1))\n",
    "# Setting the Testing length as 10%\n",
    "testinglength=int(0.1*(len(shuffledata)+1))\n",
    "# Selecting the 80% of data as Training Data \n",
    "Training_data=shuffledata[0:traininglength,0:784]\n",
    "TTarget=shuffledata[0:traininglength,784:785].astype(int)\n",
    "Training_Target=encodeTarget(TTarget)\n",
    "# Selecting the next 10% as Validation Data\n",
    "Validation_data=shuffledata[traininglength:traininglength+testinglength,0:784]\n",
    "VTarget=shuffledata[traininglength:traininglength+testinglength,784:785].astype(int)\n",
    "Validation_Target=encodeTarget(VTarget)\n",
    "# Selecting the next 10% as Testing Data\n",
    "Testing_data=shuffledata[traininglength+testinglength:len(shuffledata),0:784]\n",
    "TestTarget=shuffledata[traininglength+testinglength:len(shuffledata),784:785].astype(int)\n",
    "Testing_Target=encodeTarget(TestTarget)\n",
    "print('MNIST Data Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPS Data Generated\n"
     ]
    }
   ],
   "source": [
    "dataframe=pd.read_csv('USPS.csv')\n",
    "# Randomizing the data\n",
    "shuffleuspsdata = np.array(dataframe.sample(frac=1))\n",
    "# Selecting the 784 features from file\n",
    "USPSData=shuffleuspsdata[:,0:784]\n",
    "# Selecting the Target value\n",
    "USPSTarget=shuffleuspsdata[:,784:785]\n",
    "# Encoding the Target value using one to k encoding technique\n",
    "USPSEncodeTarget=encodeTarget(USPSTarget)\n",
    "print('USPS Data Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix (Actual Class*Predicted Class)\n",
    "def confusionMatrix(predictedData,actualData):\n",
    "    predictedData=predictedData.astype(int)\n",
    "    actualData=actualData.astype(int)\n",
    "    matrix=np.zeros((10,10)).astype(int)\n",
    "    for i in range(0,len(predictedData)):\n",
    "        if(int(predictedData[i])==int(actualData[i])):\n",
    "           num=int(predictedData[i])\n",
    "           temp=int(matrix[num][num])\n",
    "           matrix[num][num]=temp+1\n",
    "        else:\n",
    "           num=int(actualData[i])\n",
    "           num1=int(predictedData[i])\n",
    "           temp=int(matrix[num1][num])\n",
    "           matrix[num1][num]=temp+1\n",
    "    return matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Activation Function \n",
    "def softmax(z):\n",
    "    finalsoftmax=[]\n",
    "    for i in range(0,len(z)):\n",
    "        x=np.transpose(z[i].reshape((-1,1)))\n",
    "        t=[]\n",
    "        sum=0\n",
    "        for j in range(0,len(np.transpose(x))):\n",
    "            t.append(np.exp(x[0][j]))\n",
    "            sum=sum+np.exp(x[0][j])\n",
    "        softmax=[]\n",
    "        for k in range(0,len(t)):\n",
    "            if(sum!=0.0):\n",
    "               softmax.append(t[k]/sum)\n",
    "            else:\n",
    "               softmax.append(t[k])\n",
    "        finalsoftmax.append(softmax)\n",
    "    return np.array(finalsoftmax)\n",
    "# Calculating the Weight Derivative\n",
    "def weightderivative(a,y,X):\n",
    "    X=X.reshape((-1,1))\n",
    "    diff=np.subtract(a,y).reshape((-1,1))\n",
    "    return np.dot(diff,np.transpose(X))\n",
    "# Updating the wieght\n",
    "def updatedweigth(lr,dw,W):\n",
    "    return np.subtract(W,lr*dw)\n",
    "# Calculating the product of W and X transpose\n",
    "def geneticequation(W,X):\n",
    "    return np.dot(W,np.transpose(X))\n",
    "# Stochastic Gradient Descent Logistic Regression\n",
    "def logisticregression(learningrate,TrainingData,TrainingTarget,iteration):\n",
    "    W_Now = np.zeros((10,784))\n",
    "    Y=geneticequation(W_Now,TrainingData)\n",
    "    a=softmax(np.transpose(Y))\n",
    "    for i in range(0,iteration):\n",
    "        deltaW=weightderivative(a[i],TrainingTarget[i],TrainingData[i])\n",
    "        W_Now=updatedweigth(learningrate,deltaW,W_Now)\n",
    "    return W_Now\n",
    "def calAccuracy(expdata,actdata):\n",
    "    count=0\n",
    "    for i in range(0,len(expdata)):\n",
    "        num=np.argmax(expdata[i])\n",
    "        for j in range(0,10):\n",
    "            if(actdata[i][j]==1):\n",
    "               if(j==num):\n",
    "                  count=count+1;\n",
    "                  break;\n",
    "    return (count/len(actdata))*100\n",
    "def lossfunction(Actual,Expected):\n",
    "    sum=0\n",
    "    product=0\n",
    "    for i in range(0,len(Actual)):\n",
    "        expectedclass=np.argmax(Expected[i])\n",
    "        actualclass=np.argmax(Actual[i])\n",
    "        if(expectedclass!=0):\n",
    "           product=actualclass*(np.log(expectedclass))\n",
    "        sum=sum+product\n",
    "    return (-sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Logistic Regression------------------------\n",
      "Training Accuracy on MNIST dataset:70.95535714285714\n",
      "Validation Accuracy on MNIST dataset:70.64285714285714\n",
      "Testing Accuracy on MNIST dataset:70.9244177739677\n",
      "USPS Accuracy: 23.087308730873087\n"
     ]
    }
   ],
   "source": [
    "print('---------------------Logistic Regression------------------------')\n",
    "learningrate=0.01\n",
    "iteration=4000\n",
    "# Performing Stochastic Gradient logistic Regression\n",
    "W_Now=logisticregression(learningrate,Training_data,Training_Target,iteration)\n",
    "Y=geneticequation(W_Now,Training_data)\n",
    "c=softmax(np.transpose(Y))\n",
    "print('Training Accuracy on MNIST dataset:'+str(calAccuracy(c,Training_Target)))\n",
    "Y=geneticequation(W_Now,Validation_data)\n",
    "c=softmax(np.transpose(Y))\n",
    "print('Validation Accuracy on MNIST dataset:'+str(calAccuracy(c,Validation_Target)))\n",
    "Y=geneticequation(W_Now,Testing_data)\n",
    "c=softmax(np.transpose(Y))\n",
    "print('Testing Accuracy on MNIST dataset:'+str(calAccuracy(c,Testing_Target)))\n",
    "Y=geneticequation(W_Now,USPSData)\n",
    "c=softmax(np.transpose(Y))\n",
    "print('USPS Accuracy: '+str(calAccuracy(c,USPSEncodeTarget)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-11196ec0a379>:22: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b9c94cf20040eba6c7c2cf507429ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the input,hidden and output neurons of respective layer\n",
    "inputlayer=784\n",
    "hiddenlayer=10\n",
    "outputlayer=10\n",
    "LEARNING_RATE = 0.50\n",
    "NUM_OF_EPOCHS=10\n",
    "BATCH_SIZE=128\n",
    "training_accuracy=[]\n",
    "validation_accuracy=[]\n",
    "testing_accuracy=[]\n",
    "USPS_accuracy=[]\n",
    "# Setting the input and output tensor\n",
    "inputTensor=tf.placeholder(tf.float32,[None,inputlayer])\n",
    "outputTensor=tf.placeholder(tf.float32,[None,outputlayer])\n",
    "# Intializing the variables\n",
    "def init_weights(shape):\n",
    "        return tf.Variable(tf.random_normal(shape,stddev=0.01))\n",
    "input_hidden_weights  = init_weights([inputlayer, hiddenlayer])\n",
    "hidden_output_weights = init_weights([hiddenlayer, outputlayer])\n",
    "hidden_layer = tf.nn.sigmoid(tf.matmul(inputTensor, input_hidden_weights))\n",
    "output_layer = tf.matmul(hidden_layer, hidden_output_weights)\n",
    "error_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)\n",
    "prediction = tf.argmax(output_layer, 1)\n",
    "# Starting the session\n",
    "with tf.Session() as sess:\n",
    "     tf.global_variables_initializer().run()\n",
    "     for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "         p=np.random.permutation(range(len(Training_data)))\n",
    "         processedTrainingData  = Training_data[p]\n",
    "         processedTrainingLabel = Training_Target[p]\n",
    "         for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "             end = start + BATCH_SIZE\n",
    "             # Training the model\n",
    "             sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTrainingLabel[start:end]})\n",
    "     # Predicting the model and calculating the accuracy \n",
    "     training_accuracy.append(np.mean(np.argmax(processedTrainingLabel, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTrainingLabel})))\n",
    "     validation_accuracy.append(np.mean(np.argmax(Validation_Target, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: Validation_data,\n",
    "                                                             outputTensor: Validation_Target})))\n",
    "     testing_accuracy.append(np.mean(np.argmax(Testing_Target, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: Testing_data,\n",
    "                                                             outputTensor: Testing_Target})))\n",
    "     testing_predicted=sess.run(prediction, feed_dict={inputTensor: Testing_data,\n",
    "                                                             outputTensor: Testing_Target})\n",
    "     USPS_accuracy.append(np.mean(np.argmax(USPSEncodeTarget, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: USPSData,\n",
    "                                                             outputTensor: USPSEncodeTarget})))\n",
    "print('------------------------Neural Network---------------------------')\n",
    "print('MNIST Training Accuracy '+str(np.mean(training_accuracy)*100))\n",
    "print('MNIST Validation Accuracy '+str(np.mean(validation_accuracy)*100))\n",
    "print('MNIST Testing Accuracy '+str(np.mean(testing_accuracy)*100))\n",
    "print('USPS Accuracy '+str(np.mean(USPS_accuracy)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shmis\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Training Accuracy: 0.9562678571428571\n",
      "MNIST Validation Accuracy: 0.9391428571428572\n",
      "MNIST Testing Accuracy: 0.9397056722388912\n",
      "[[606   0   4   2   0   4   2   1   2   3]\n",
      " [  0 791   0   1   4   5   2   3  15   2]\n",
      " [  5   6 647  17   6   8   5  11   9   6]\n",
      " [  2   2   8 658   0  19   0   1  20   6]\n",
      " [  2   0  13   2 677   3   4  10   3  13]\n",
      " [  2   0   1  16   0 571  10   2  23   3]\n",
      " [  3   0   8   1   3   8 659   0   5   1]\n",
      " [  0   2   5   4   2   0   0 688   3  14]\n",
      " [  2   5  16   7   1   9   0   1 643   1]\n",
      " [  0   0   0   4  13   2   0  10   4 637]]\n",
      "USPS Accuracy: 0.3499349934993499\n"
     ]
    }
   ],
   "source": [
    " # SVC is Support Vector Class of SVM library used for classification problem\n",
    " # Kernel parameter specifies whether to use linear or non linear classifier\n",
    " # rbf passed to implement Gaussian Kernel \n",
    " classifier1 = SVC(kernel='linear',C=0.05)\n",
    " # Fit method is used to Train the Algorithm\n",
    " classifier1.fit(Training_data, TTarget)\n",
    "# Predict method is used to make the Predictions\n",
    "# Predicting the Output on Training,Validation,Testing and USPS dataset\n",
    " Trainingpredicted=classifier1.predict(Training_data)\n",
    " print('------------------------------SVM Classifier----------------------------')\n",
    " print('MNIST Training Accuracy: '+str(accuracy_score(TTarget,Trainingpredicted)))\n",
    " Validationpredicted=classifier1.predict(Validation_data)\n",
    " print('MNIST Validation Accuracy: '+str(accuracy_score(VTarget,Validationpredicted)*100))\n",
    " Testingpredicted=classifier1.predict(Testing_data)\n",
    " print('MNIST Testing Accuracy: '+str(accuracy_score(TestTarget,Testingpredicted)*100))\n",
    " print(confusionMatrix(Testingpredicted,TestTarget))\n",
    " USPSpredicted=classifier1.predict(USPSData)\n",
    " print('USPS Accuracy: '+str(accuracy_score(USPSTarget,USPSpredicted)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shmis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Training Accuracy: 99.9875\n",
      "MNIST Validation Accuracy: 95.97142857142858\n",
      "MNIST Testing Accuracy: 96.2280325760823\n",
      "USPS Accuracy: 35.243524352435244\n",
      "[[663   1   2   1   2   1   2   0   0   4]\n",
      " [  1 778   2   1   1   0   1   2   4   1]\n",
      " [  0   3 684  11   0   1   2   7   7   4]\n",
      " [  1   0   6 649   0  13   0   0   5  11]\n",
      " [  1   1   4   0 673   0   1   3   3  10]\n",
      " [  1   1   0   9   1 600   3   0   9   2]\n",
      " [  2   0   1   0   4   5 687   0   3   1]\n",
      " [  0   2   8   6   3   2   0 705   1   7]\n",
      " [  1   0   3   8   1  10   3   3 633   7]\n",
      " [  1   0   0   5   9   2   1   9  10 663]]\n"
     ]
    }
   ],
   "source": [
    "# Since we are using Random Forest for classification problem \n",
    "classifier2 = RandomForestClassifier(n_estimators=20)\n",
    "classifier2.fit(Training_data, TTarget)\n",
    "Trainingpredicted=classifier2.predict(Training_data)\n",
    "print('MNIST Training Accuracy: '+str(accuracy_score(TTarget,Trainingpredicted)*100))\n",
    "Validationpredicted=classifier2.predict(Validation_data)\n",
    "print('MNIST Validation Accuracy: '+str(accuracy_score(VTarget,Validationpredicted)*100))\n",
    "Testingpredicted=classifier2.predict(Testing_data)\n",
    "print('MNIST Testing Accuracy: '+str(accuracy_score(TestTarget,Testingpredicted)*100))\n",
    "USPSpredicted=classifier2.predict(USPSData)\n",
    "print('USPS Accuracy: '+str(accuracy_score(USPSTarget,USPSpredicted)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(W_Now,classifier1,classifier2,combinationData,combinationTarget):\n",
    "    models=[]\n",
    "    finaldata=[]\n",
    "    Y=geneticequation(W_Now,combinationData)\n",
    "    c=np.transpose(softmax(Y))\n",
    "    d=np.argmax(c,1)\n",
    "    encodeCombine=encodeTarget(combinationTarget)\n",
    "    with tf.Session() as sess:\n",
    "         tf.global_variables_initializer().run()\n",
    "         NNPredicted=sess.run(prediction, feed_dict={inputTensor: combinationData, \n",
    "                                          outputTensor: encodeCombine})\n",
    "    SVMPredicted=classifier1.predict(combinationData)\n",
    "    RandomPredicted=classifier2.predict(combinationData)\n",
    "    models.append(d)\n",
    "    models.append(NNPredicted)\n",
    "    models.append(SVMPredicted)\n",
    "    models.append(RandomPredicted)\n",
    "    for i in range(0,len(combinationData)):\n",
    "        classes=np.zeros((1,10))\n",
    "        for j in range(0,len(models)):\n",
    "            model=models[j]\n",
    "            num=int(model[i])\n",
    "            temp=classes[0][num]\n",
    "            classes[0][num]=temp+1\n",
    "        finalclass=np.argmax(classes,1)\n",
    "        finaldata.append(finalclass)\n",
    "    return finaldata\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Ensemble Classifier for MNIST datset: 86.2\n",
      "Accuracy Score of Ensemble Classifier for USPS dataset: 35.0\n"
     ]
    }
   ],
   "source": [
    "# All the four classifier are trained on MNIST dataset .Now their combination is tested on subset of MNIST dataset and USPS dataset\n",
    "\n",
    "combinationData=Training_data[0:1000]\n",
    "combinationTarget=TTarget[0:1000]\n",
    "finaldata=combination(W_Now,classifier1,classifier2,combinationData,combinationTarget)\n",
    "print('Accuracy Score of Ensemble Classifier for MNIST datset: '+str(accuracy_score(finaldata,combinationTarget)*100))\n",
    "combinationData=USPSData[0:1000]\n",
    "combinationTarget=USPSTarget[0:1000]\n",
    "finaldata=combination(W_Now,classifier1,classifier2,combinationData,combinationTarget)\n",
    "print('Accuracy Score of Ensemble Classifier for USPS dataset: '+str(accuracy_score(finaldata,combinationTarget)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
